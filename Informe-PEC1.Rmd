---
title: "PEC 1"
author: "Joan Canseco i Ribas"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract
En este proyecto, se ha llevado a cabo un análisis estructurado de datos metabolómicos para simular un proceso de análisis ómico. El objetivo ha sido familiarizarse con la organización y manejo de datos ómicos, aplicando diversas herramientas y métodos que se han ido mostrando durante la asignatura de "Análisis de datos ómicos". Para ello, se ha seleccionado un conjunto de datos de un estudio en el que se investiga los metabolitos en respuesta a la cirugía bariátrica en 4 distintos timepoints en 39 pacientes con más de 10 años de obesidad. Estos 39 pacientes están clasificados en dos grupos, un grupo de pacientes que se les aplica cirugía by pass (n=26) y otro que se les aplica cirugía tubular (n=13).
Estos datos han sido organizados en un contenedor del tipo SummarizedExperiment para facilitar el trabajo con este dataset. Además, se han realizado análisis exploratorios en el que se han reflejado las características más relevantes del proyecto. También se han estudiado las características de los principales grupos de estudio, y se han comparado las diferencias de metabolitos entre el timepoint 0 y el timepoint 5 entre los dos tipos principales de cirugías para verificar cuáles son los metabolitos que más cambian al aplicar una u otra cirugía. En esta última prueba se han detectado 9 metabolitos con diferencias significativas entre cirugías.
Finalmente, se ha creado un repositorio del proyecto en Github donde se han subido todos los documentos del proyecto.

# Objetivos del estudio
Los objetivos generales de esta actividad son planificar y ejecutar una versión simplificada del proceso de análisis de datos ómicos, utilizando algunas de las herramientas y métodos que se han trabajado en la unidad. En concreto, se deberá:

* Seleccionar un dataset de un repositorio de github de metabolómica <https://github.com/nutrimetabolomics/metaboData/>.

* Crear un contenedor del tipo *SummarizedExperiment* que contenga los datos y metadatos del dataset.

* Llevar a cabo una exploración del dataset que dé una visión general del mismo.

* Elaborar un informe que describa el proceso realizado (este documento).

* Crear un repositorio en Github y subir el informe, el objeto contenedor con los datos y metadatos, el código R para la exploración de los datos, los datos y los metadatos.


# Materiales y Métodos
Esta actividad se ha desarrollado desde un ordenador Windows.

## Origen y naturaleza de los datos
Los datos analizados han sido extraídos del siguiente repositorio online: <https://github.com/nutrimetabolomics/metaboData/>
Una vez accedemos a dicho repositorio, clicamos el botón verde "<> Code", y clicamos la opción "Download ZIP". Una vez se ha descargado el repositorio en nuestro ordenador, clicamos botón derecho y seleccionamos "Extraer todo". Exploramos los distintos datasets y seleccionamos el dataset "2018-MetabotypingPaper" porque tiene los documentos bien estructurados y parece que se puede trabajar bien con él. Cogemos los documentos de dicho dataset y los llevamos a nuestro directorio de trabajo de la PEC1. 
Se trata de un dataset de un estudio de 39 pacientes con más de 10 años de obesidad a los que se les ha realizado una cirugía bariátrica. Se clasifica el dataset en 2 grupos según la cirugía bariátrica recibida: grupo "by pass" compuesto por 26 pacientes y grupo "tubular" compuesto por 13 pacientes. También se recoge su estado metabólico, en cuanto a si los pacientes estaban sanos o enfermos metabólicamente en la variable Group. En estos pacientes se pretende estudiar como evolucionan ciertos metabolitos en 4 distintos timepoints tras la cirugía según qué cirugía hayan tomado. 

## Herramientas informáticas
Se han usado principalmente 3 herramientas informáticas y bioinformáticas para la resolución de la PEC1:

* R y Rstudio: Se ha usado para realizar la exploración del dataset para obtener una visión general del mismo. Además, se ha usado para la redacción del informe, usando Rmarkdown.

* Bioconductor: Aunque es un paquete de R, lo consideraremos como una herramienta independiente para hacer esta explicación. Bioconductor se ha usado para crear un contenedor del tipo *SummarizedExperiment*.

* Github: Se ha usado para la descarga de los datos (ya se ha indicado en la sección previa el procedimiento realizado), y se ha usado para presentar los resultados complementarios de la PEC1.

## Creación de un contenedor del tipo SummarizedExperiment
Para la creación del contenedor se ha usado Bioconductor dentro de R (como se ha especificado anteriormente). Los pasos se han especificado en el apartado de Resultados.

## Exploración del dataset
Para la exploración de los datos se usará principalmente R y Rstudio. Se usará en este proyecto dos documentos:

* "DataValues_S013.csv": Se trata del documento donde hay almacenados los datos experimentales de los pacientes. Es un data frame con 39 filas (de 39 pacientes) y 696 variables. De las 696 variables, las 6 primeras son para identificar a los pacientes (X.1, SUBJECTS, SURGERY, AGE, GENDER y Group, en la que X.1 es un duplicado de SUBJECTS, por lo que realmente se podría considerar solo las 5 primeras columnas), y el resto de variables son los metabolitos tomados en 4 timepoints distintos (T0, T2, T4 y T5). Se denota a qué timepoint hace referencia cada variable porque al final del nombre de cada variable hay especificado el timepoint al que pertenecen con "_TX" (donde X es 0, 2, 4 o 5).

* "DataInfo_S013.csv": Se trata de un documento donde hay la metadata del documento anterior y está organizado de manera distinta. Tiene solo 4 columnas (X, es un duplicado de VarName, VarName, contiene el nombre de cada una de las variables del documento anterior, varTpe, especifica el tipo de variable que es, y Description, especifica qué información se recoge en cada variable) y 695 filas, correspondientes a las 695 variables del documento anterior (recordemos que eran 696 pero la primera columna era un duplicado de la segunda columna, por lo que son 695 efectivas).
Una exploración más exhaustiva será llevada a cabo en el apartado de Resultados. En esta exploración se realizará un análisis inicial de los datos. Además, se estudiarán las variables identificativas de los pacientes, centrando el foco sobretodo en el tipo de cirugía realizada en el paciente. Finalmente, también estudiaremos las diferencias entre el T0 y el T5 entre tipo de cirugía, ya que nos interesa ver como han variado los metabolitos tras la cirugía en un grupo y en otro para saber qué efectos diferentes sucede en una cirugía y en otra.

## Creación del repositorio Github
Primeramente, se ha creado un nuevo repositorio online llamado "Canseco-i-Ribas-Joan-PEC1" desde el usuario "CansecoRibas". 
Dentro del directorio local del proyecto (donde hay todos los documentos que se han ido mencionando en la parte de "Materiales y Métodos"), se ha creado primeramente un proyecto de R, para facilitar el trabajo con estos documentos. Posteriormente, y desde la Terminal de Rstudio, se ha creado un repositorio local Git usando el comando "git init". Después se ha establecido conexión con el repositorio online con "git remote add origin https://github.com/CansecoRibas/Canseco-i-Ribas-Joan-PEC1.git". Se han añadido todos los documentos al área de ensayo con "git add ." y se ha hecho el primer commit con "git commit -m 'Primer commit del proyecto'". Seguidamente, se han enviado todos los documentos del repositorio local al repositorio online con "git push origin master".
Una vez se han vinculados los repositorios, se han ido haciendo commits a medida que se ha ido avanzando en el proyecto.
Se puede acceder al repositorio online desde: <https://github.com/CansecoRibas/Canseco-i-Ribas-Joan-PEC1>

# Resultados
En este apartado se volcarán los resultados del proyecto.

## Creación del contenedor del tipo SummarizedExperiment
El primer paso será asegurarnos de que "BiocManager" está instalado:
```{r message=FALSE, warning=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")
```

Posteriormente instalamos desde Bioconductor el paquete "SummarizedExperiment" que es el paquete específico para crear el contendor.
```{r message=FALSE, warning=FALSE}
if (!requireNamespace("SummarizedExperiment", quietly = TRUE)) BiocManager::install("SummarizedExperiment")
```

Y lo llamamos con library.
```{r message=FALSE, warning=FALSE}
library("SummarizedExperiment")
```


Ahora cargamos los datos ("DataValues_S013.csv") y los metadatos ("DataInfo_S013.csv") del dataset que están dentro de la carpeta "2018-MetabotypingPaper".
```{r}
data_values <- read.csv("2018-MetabotypingPaper/DataValues_S013.csv")
metadata <- read.csv("2018-MetabotypingPaper/DataInfo_S013.csv")
```

Observamos estos dos archivos. Posteriormente ya se hará una mejor exploración de los datos en próximos apartados. Dejamos este código en forma de comentarios porque sinó el informe se llena de datos densos.
```{r}
#head(data_values)
#head(metadata)
```

En estos dos documentos hay dos variables iniciales que sobran, ya que son duplicaciones de las columnas adyacentes. Estas columnas son X.1 en "DataValues_S013.csv" y X en "DataInfo_S013.csv", por lo que las vamos a eliminar para que no nos molesten.
```{r}
data_values_mod <- data_values[, 2:696]
metadata_mod <- metadata[, 2:4]
```

Vemos que hay algunas variables identificativas (las 5 primeras) en el documento "DataValues_S013.csv" y el resto son variables experimentales. En el documento "DataInfo_S013.csv" se recoge información de las variables del documento "DataValues_S013.csv". Algunas de las variables son las mismas pero en distintos timepoints por lo que vamos a crear una nueva variable que especifique el timepoint. De esta manera, conseguiremos obtener muestras de manera individual para las variables. Primero nos aseguramos que los paquetes dplyr y tidyr estén instalados.
```{r message=FALSE, warning=FALSE}
if (!requireNamespace("tidyr", quietly = TRUE)) install.packages("tidyr")
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
```

Los llamamos con library.
```{r message=FALSE, warning=FALSE}
library("tidyr")
library("dplyr")
```

Creamos una nueva variable que se llame Timepoint haciendo pivot_longer para así obtener las muestras de manera individual que es lo que nos interesa.
```{r warning=FALSE}
data_values_samples <- data_values_mod %>%
  # Hacemos pivot_longer para transformar el df.
  pivot_longer(
    cols = 6:695, # Seleccionamos las columnas de metabolitos.
    names_to = c(".value", "Timepoint"), # Extraemos los metabolitos como 
    #columnas y establecemos timepoints como nueva columna.
    names_sep = "_T" # Establecemos el separador entre el nombre del metabolito
    # y el timepoint.
  ) %>%
  # Especificamos como queremos que se muestren los timepoints.
  mutate(Timepoint = paste0("T", Timepoint)) %>% 
  filter(!Timepoint == "TNA") # Eliminamos las filas que se nos han creado por 
# error que están completamente vacías.
```

Ahora modificamos el metadata para adecuarlo a las nuevas variables. Primero añadimos la nueva fila de timepoints creando un nuevo df.
```{r}
metadata_timepoints <- data.frame(
  VarName = "Timepoint",
  varTpe = "character",
  Description= "Punto temporal de recogida de muestra del paciente (0, 2, 4 o 5)"
)
```

Modificamos las variables del metadata eliminando "_TX" del final y eliminamos variables repetidas.
```{r}
metadata_metabolites <- metadata_mod %>%
  mutate(VarName = gsub("_T[0-5]$", "", VarName)) %>% # Buscamos y eliminamos el "_TX" del final.
  distinct(VarName, .keep_all = TRUE)  # Quitamos las variables repetidas en Varname.
```

Finalmente unimos los dos dfs con rbind.
```{r}
# Finalmente unimos los dos dfs con rbind.
metadata_samples <- rbind(metadata_timepoints, metadata_metabolites)
```

Vemos que metadata_samples tiene las mismas filas que columnas tiene data_values_samples que es lo que estábamos buscando.
```{r}
dim(metadata_samples)
dim(data_values_samples)
```

Una vez modificados ambos documentos, nos quedan los datos separados por muestras individuales cogidas en diferentes timepoints. Ahora ya podemos crear el objeto "SummarizedExperiment". Vemos también que las 4 columnas posteriores a las 6 columnas identificativas de muestra también recogen un factor asociado a la muestra, por lo que también sería interesante sacarlas del metabolite_data.
Para ello, seleccionamos las variables experimentales (a partir de la variable 11 hasta el final) y creamos una matriz transpuesta llamada "metabolite_data", ya que las filas deben ser las variables y las columnas deben ser las distintas muestras.
```{r}
metabolite_data <- t(as.matrix(data_values_samples[, 11:ncol(data_values_samples)]))
```

Creamos rowData a partir de la información de la metadata para especificar la información de las variables experimentales.
```{r}
rowData <- metadata_samples[11:nrow(metadata_samples), ]
```

Creamos ColData seleccionando las variables de identificación de los pacientes.
```{r}
colData <- data_values_samples[, 1:10]
```

Creamos el objeto *SummarizedExperiment* con los 3 componentes que hemos mencionado.
```{r}
sum_exp_object <- SummarizedExperiment(
  assays = list(counts = metabolite_data),
  rowData = rowData,
  colData = colData
)
```

Vemos qué pinta tiene.
```{r}
sum_exp_object
```

Vemos que es un objeto con 174 filas (variables experimentales de metabolitos) y 156 columnas, que son las muestras (4 para cada paciente, ya que son 4 timepoints). Se puede estudiar un poco más el objeto con las siguientes funciones, pero las dejaremos como comentarios para que no se muestren unos tochos terribles en el informe.
```{r}
#assay(sum_exp_object) # Devuelve la matriz principal de datos.
#rowData(sum_exp_object) # Devuelve un df con información sobre los metabolitos 
#(filas de la matriz).
#colData(sum_exp_object) # Devuelve un df con información sobre las muestras 
#(columnas de la matriz).
```

Solo queda guardar el objeto tal y como nos pide el enunciado.
```{r}
save(sum_exp_object, file = "sum_exp_object.Rda")
```

## Exploración del dataset
Empezamos con el análisis de ambos documentos, "DataValues_S013.csv" y "DataInfo_S013.csv". Como se ha indicado anteriormente, el primero contiene los datos en relación a los metabolitos recogidos en muestras de 4 distintos timepoints de 39 pacientes, y el segundo contiene la explicación de las características de las variables y su información. Por lo que nos fijaremos para hacer los análisis en el primer documento ("DataValues_S013.csv").

### Análisis preliminar
Primero haremos una exploración inicial. Cogeremos el documento data_values_samples, en el que hemos transformado los datos para que las filas sean las muestras recogidas (y no los pacientes como antes). Verificaremos las dimensiones del documento para ver si lo que se cumple es cierto.
```{r}
dim(data_values_samples)
```

Vemos que es un documento con 156 filas (correspondiente a los 4 timepoints de los 39 pacientes) y 180 columnas (correspondientes a las variables de estudio). Hacemos ahora un resumen estadístico muy básico de las 180 variables para ver qué valores toman y qué tipos de variables tenemos. Es un poco complicado trabajar con este número tan elevado de variables ya que los outputs son enormes, por lo que en este caso tampoco vamos a mostrar el resultado.
```{r}
#summary(data_values_samples)
```

También es importante verificar los missings de los datos. Vamos a mirar cuantos missings hay por cada variable.
```{r}
colSums(is.na(data_values_samples))
```
Vemos que las variables identificativas están completas, mientras que todas las variables de metabolitos tienen algún missing, aunque en general son pocos (la mayoría tienen menos de 19 missings de 156 valores totales). Además, hay una variable "X" que son todo missings, por lo que la podemos eliminar.
```{r}
data_values_samples <- data_values_samples[, -which(names(data_values_samples) == "X")]
```


### Análisis de los pacientes
Como hay muchas variables de metabolitos, haremos una exploración inicial de las variables identificativas de los pacientes, que, como hemos dicho son las 5 primeras variables (excluyendo la variable Timepoint que en este caso no tiene mucho sentido mantenerla porque hace referencia a las muestras).
```{r}
data_values_patients <- data_values_samples %>% 
  select("SUBJECTS", "SURGERY", "AGE", "GENDER", "Group") %>% # Seleccionamos columnas
  distinct() # Eliminamos duplicados de pacientes
```

Verificamos que tenemos 39 pacientes en este df.
```{r}
nrow(data_values_patients)
```

Verificamos las variables que deban ser factors realmente sean factors.
```{r}
data_values_patients$SURGERY <- factor(data_values_patients$SURGERY)
data_values_patients$GENDER <- factor(data_values_patients$GENDER)
data_values_patients$Group <- factor(data_values_patients$Group)
```

Ahora podemos hacer estadística básica con estos datos de los pacientes. Los datos realmente importantes de este df se encuentran en las variables "SURGERY", "AGE", "GENDER" y "Group", ya que "SUBJECTS" solo hace referencia al número de paciente. La variable "AGE" la veremos con un histograma mientras que los factores los veremos con diagramas de barras.
```{r warning=FALSE}
par(mfrow = c(2,2)) # Así podemos ver los 4 gráficos a la vez.
# Histograma de la edad.
hist(data_values_patients$AGE, 
     main="Distribución de edades", 
     col="blue", 
     xlab="Edad en años",
     ylab="Frecuencia")

# Diagrama de barras para el género.
barplot(table(data_values_patients$GENDER), 
        main="Distribución por género", 
        col="red", 
        xlab="Género",
        ylim=c(0,30))

# Diagrama de barras para el grupo.
barplot(table(data_values_patients$Group), 
        main="Distribución por grupo", 
        col="green", 
        xlab="Grupo",
        ylim=c(0,30))

# Diagrama de barras para la cirugía.
barplot(table(data_values_patients$SURGERY), 
        main="Distribución por cirugía", 
        col="pink", 
        xlab="Cirugía",
        ylim=c(0,30))
```

Estos gráficos muestran que la mayoría de edades de los participantes están entre los 30 y los 50 años, que hay el doble de mujeres que de hombres, que hay más componentes del grupo 1 que del grupo 2 y que hay más pacientes con cirugía by pass que tubular. Ahora miraremos la relación entre la variable SURGERY (la variable que indica el tipo de cirugía que ha tomado cada paciente) y las demás, ya que la variable SURGERY es la variable clave del estudio.
```{r}
# Separamos los datos según la variable SURGERY.
split_data <- split(data_values_patients, data_values_patients$SURGERY)

# Redistribuimos el espacio gráfico.
par(mfrow = c(2, 3)) 

# Hacemos loop.
for (surgery_status in names(split_data)) {
  data_subset <- split_data[[surgery_status]]
  
  # Histograma de la edad.
  hist(data_subset$AGE,
       main=paste("Edades (", surgery_status, ")"), 
       col="blue", 
       xlab="Edad en años",
       ylab="Frecuencia")
  
  # Diagrama de barras para el género.
  barplot(table(data_subset$GENDER), 
          main=paste("Género (", surgery_status, ")"), 
          col="red", 
          xlab="Género",
          ylim=c(0,30))
  
  # Diagrama de barras para el grupo.
  barplot(table(data_subset$Group), 
          main=paste("Grupo (", surgery_status, ")"), 
          col="green", 
          xlab="Grupo",
          ylim=c(0,30))
}
```

Vemos que los grupos son bastante diferentes entre ellos, también probablemente porque la n es relativamente pequeña, aun que no sabemos si puede afectar a nuestros resultados. 

### Análisis
Se propone dilucidar qué metabolitos varían más desde el T=0 hasta el T=5 (el último timepoint que hay) en cada una de las cirugías (bypass y tubular). Para ver eso, primero vamos a verificar que las columnas de metabolitos sean numéricas, y sinó, las eliminaremos para este análisis.
```{r}
numeric_cols <- sapply(data_values_samples, is.numeric)
data_values_samples_num <- data_values_samples[, numeric_cols | colnames(data_values_samples) %in% c("SUBJECTS", "SURGERY", "AGE", "GENDER", "Group", "Timepoint", "MEDDM", "MEDCOL", "MEDINF", "MEDHTA")]
```


Parece que todas ellas son numéricas. Nos quedamos solo con las muestras de los timepoints 0 y 5. También eliminamos las columnas "MEDDM", "MEDCOL", "MEDINF" y "MEDHTA", ya que son factores asociados a las muestras, que para este análisis no nos van a interesar.
```{r}
data_values_timepoints <- data_values_samples_num[data_values_samples_num$Timepoint %in% c("T0", "T5"), -c(7:10)]
```

Creamos un df para almacenar las diferencias de metaboitos entre timepoints.
```{r}
data_values_difference <- data.frame()
```

Calculamos la diferencia entre metabolitos para cada paciente (columnas 7 hasta el final).
```{r warning=FALSE}
for (patient in unique(data_values_timepoints$SUBJECTS)) {
  patient_data <- data_values_timepoints[data_values_timepoints$SUBJECTS == patient, ]
  
  # Verificamos que los pacientes tengan ambos timepoints.
  if (all(c("T0", "T5") %in% patient_data$Timepoint)) {
    tp0 <- patient_data[patient_data$Timepoint == "T0", ]
    tp5 <- patient_data[patient_data$Timepoint == "T5", ]
    
    # Copiamos tp5 a diff_row.
    diff_row <- tp5
    # Computamos diferencias en metabolitos entre t5 y t0.
    diff_row[, 7:ncol(tp5)] <- tp5[, 7:ncol(tp5)] - tp0[, 7:ncol(tp0)]
    # Establecemos valor de columna Timepoint.
    diff_row$Timepoint <- "Difference between T5 and T0"
    
    # Unimos dfs.
    data_values_difference <- rbind(data_values_difference, diff_row)
  }
}
```

Creamos vector con los nombres de las columnas de los metabolitos.
```{r}
metabolite_columns <- colnames(data_values_samples_num)[11:ncol(data_values_samples_num)]  
```

Cremos un df para almacenar los resultados significativos.
```{r}
significant_results <- data.frame(Metabolite = character(), 
                                  Test = character(),
                                  p_value = numeric(), 
                                  stringsAsFactors = FALSE)
```

Para cada metabolito comparamos los valores de las diferencias entre el T0 y el T5 entre ambos grupos (by pass y tubular) usando un t-test (en caso de normalidad de los datos) o un test de Wilcoxon (en caso de no normalidad de los datos). Posteriormente calculamos las medias de cada uno de los grupos, y en caso de que el test calculado muestre diferencias significativas del metabolito entre grupos, se reflejará en el df creado como "significant_results".
```{r warning=FALSE}
for (metabolite in metabolite_columns) {
  # Dividimos las diferencias por tipo de cirugía y eliminamos los NA.
  bypass_values <- na.omit(data_values_difference[data_values_difference$SURGERY == "by pass", metabolite])[[1]]
  tubular_values <- na.omit(data_values_difference[data_values_difference$SURGERY == "tubular", metabolite])[[1]]
  
  # Verificamos que tengan más de una muestra.
  if (length(bypass_values) > 1 & length(tubular_values) > 1) {
    # Prueba de normalidad.
    normality_test <- shapiro.test(c(bypass_values, tubular_values))$p.value > 0.05
    
    # Realizamos una prueba u otra según los resultados de normalidad.
    if (normality_test) {
      test_result <- t.test(bypass_values, tubular_values)
      test_type <- "t-test"
    } else {
      test_result <- wilcox.test(bypass_values, tubular_values)
      test_type <- "Wilcoxon"
    }
    
    # Calculamos las medias de cada grupo.
    mean_bypass <- mean(bypass_values, na.rm = TRUE)
    mean_tubular <- mean(tubular_values, na.rm = TRUE)
    
    # Guardamos solo los resultados si el test es significativo.
    if (test_result$p.value < 0.05) {
      significant_results <- rbind(significant_results, 
                                   data.frame(Metabolite = metabolite, 
                                              Test = test_type,
                                              p_value = test_result$p.value,
                                              Media_bypass = mean_bypass,
                                              Media_tubular = mean_tubular))
    }
  }
}
```

Finalmente, mostramos los resultados obtenidos.
```{r}
significant_results
```
Solo se han encontrado diferencias entre grupos en las diferencias de lo metabolitos "TG", "COL", "C10", "C10.1", "C14.1", "C14.2", "C16.1", "IysoPC.a.C17.0" y "IysoPC.a.C18.0", y en todos ellos en el grupo bypass hay valores inferiores de diferencia respecto al grupo tubular.
 

# Discusión y limitaciones y conclusiones del estudio
En esta actividad se ha seleccionado un dataset de un estudio de 39 pacientes con más de 10 años de obesidad a los que se les ha realizado una cirugía bariátrica. Se ha clasificado el dataset en 2 grupos según la cirugía bariátrica recibida: grupo "by pass" compuesto por 26 pacientes y grupo "tubular" compuesto por 13 pacientes. En estos pacientes se ha pretendido estudiar como evolucionan ciertos metabolitos en 4 distintos timepoints tras la cirugía según qué cirugía hayan tomado. 
Se ha creado un contenedor del tipo SummarizedExperiment para poder facilitar análisis posteriores de los datos. Posteriormente, se ha hecho un análisis inicial que indicaba que había 156 muestras de 39 pacienes y 180 variables, y que en general es un documento con pocos missings, algo importante para posteriores análisis. Después se han estudiado las variables relacionadas con los pacientes y hemos detectado diferencias visuales entre ambos grupos de cirugía, lo que podría significar que los grupos de los pacientes tengan caracterísitcas basales distintas. También se ha hecho un análisis para ver los metabolitos que evolucionan de manera distinta entre el tiempo 0 y el tiempo 5 entre los dos tipos de cirugías, y hemos visto que los metabolitos "TG", "COL", "C10", "C10.1", "C14.1", "C14.2", "C16.1", "IysoPC.a.C17.0" y "IysoPC.a.C18.0" tienen valores inferiores de diferencia en el grupo bypass respecto al grupo tubular. Una limitación importante del estudio ha sido los pocos pacientes que había para cada cirugía (by pass n =26; tubular n=13), lo que no ha permitido hacer comparaciones más avanzadas. Finalmente, se ha creado un repositorio y se han colgado todos los documentos:

<https://github.com/CansecoRibas/Canseco-i-Ribas-Joan-PEC1>








